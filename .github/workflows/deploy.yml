name: CI/CD Pipeline - Ecommerce Platform

on:
  push:
    branches: [main]
  workflow_dispatch:

env:
  DOTNET_VERSION: "9.0"
  REGISTRY_URL: ${{ secrets.REGISTRY_URL }}
  REGISTRY_USERNAME: ${{ secrets.REGISTRY_USERNAME }}
  REGISTRY_PASSWORD: ${{ secrets.REGISTRY_PASSWORD }}
  IMAGE_CORE: moclaw/ecom-core-api
  IMAGE_USERS: moclaw/ecom-users-api
  KUBE_NAMESPACE: ecommerce
  KUBECTL_TIMEOUT: 300s
  HEALTH_CHECK_TIMEOUT: 180s

jobs:
  build-and-test:
    name: Build & Test
    runs-on: ubuntu-latest
    outputs:
      image-tag: ${{ steps.meta.outputs.tags }}
      should-deploy: ${{ steps.changes.outputs.should-deploy }}

    steps:
      - name: üì• Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: üîç Check for changes
        id: changes
        run: |
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            echo "should-deploy=true" >> $GITHUB_OUTPUT
            echo "Manual trigger - will deploy"
          elif [ "${{ github.ref }}" = "refs/heads/main" ]; then
            echo "should-deploy=true" >> $GITHUB_OUTPUT
            echo "Main branch - will deploy"
          else
            if git diff --name-only HEAD~1 HEAD | grep -E "\\.(cs|csproj|sln|Dockerfile)$|^k8s/"; then
              echo "should-deploy=true" >> $GITHUB_OUTPUT
              echo "Source code changes detected - will deploy"
            else
              echo "should-deploy=false" >> $GITHUB_OUTPUT
              echo "No significant changes - skipping deployment"
            fi
          fi

      - name: üîß Setup .NET SDK
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}

      - name: üì¶ Cache NuGet packages
        uses: actions/cache@v4
        with:
          path: ~/.nuget/packages
          key: ${{ runner.os }}-nuget-${{ hashFiles('**/*.csproj', '**/*.props', '**/*.targets') }}
          restore-keys: |
            ${{ runner.os }}-nuget-

      - name: üì¶ Restore dependencies
        run: |
          dotnet restore Moclaw.Ecommerce.sln --verbosity minimal

      - name: üèóÔ∏è Build solution
        run: |
          dotnet build Moclaw.Ecommerce.sln --configuration Release --no-restore --verbosity minimal

      - name: üß™ Run tests
        run: |
          if find . -name "*.Test*.csproj" -o -name "*Test.csproj" | head -1 | grep -q .; then
            echo "Running unit tests..."
            dotnet test --configuration Release --no-build --verbosity minimal --parallel
          else
            echo "No test projects found, skipping tests"
          fi

      - name: üè∑Ô∏è Generate metadata
        id: meta
        run: |
          TAG="${{ github.sha }}"
          SHORT_SHA="${TAG:0:8}"
          echo "tags=${SHORT_SHA}" >> $GITHUB_OUTPUT

  build-images:
    name: Build Images
    runs-on: ubuntu-latest
    needs: build-and-test
    if: needs.build-and-test.outputs.should-deploy == 'true'
    strategy:
      matrix:
        service:
          - name: core-api
            dockerfile: Ecom.Core/src/Ecom.Core.API/Dockerfile
            image_name: moclaw/ecom-core-api
          - name: users-api
            dockerfile: Ecom.Users/src/Ecom.Users.API/Dockerfile
            image_name: moclaw/ecom-users-api
      fail-fast: false
      max-parallel: 2

    steps:
      - name: üì• Checkout code
        uses: actions/checkout@v4

      - name: üê≥ Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: üîê Login to Docker registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY_URL }}
          username: ${{ env.REGISTRY_USERNAME }}
          password: ${{ env.REGISTRY_PASSWORD }}

      - name: üèóÔ∏è Build and push ${{ matrix.service.name }}
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ${{ matrix.service.dockerfile }}
          push: true
          tags: |
            ${{ matrix.service.image_name }}:${{ needs.build-and-test.outputs.image-tag }}
            ${{ matrix.service.image_name }}:latest
          platforms: linux/amd64
          cache-from: type=registry,ref=${{ matrix.service.image_name }}:buildcache
          cache-to: type=registry,ref=${{ matrix.service.image_name }}:buildcache,mode=max
          build-args: |
            BUILDKIT_INLINE_CACHE=1

  deploy-minikube:
    name: Deploy to Minikube
    runs-on: self-hosted
    needs: [build-and-test, build-images]
    if: needs.build-and-test.outputs.should-deploy == 'true'

    steps:
      - name: üì• Checkout code
        uses: actions/checkout@v4

      - name: üîê Login to Docker registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY_URL }}
          username: ${{ env.REGISTRY_USERNAME }}
          password: ${{ env.REGISTRY_PASSWORD }}

      - name: üöÄ Deploy to Minikube
        env:
          CORE_IMAGE: ${{ env.IMAGE_CORE }}:${{ needs.build-and-test.outputs.image-tag }}
          USERS_IMAGE: ${{ env.IMAGE_USERS }}:${{ needs.build-and-test.outputs.image-tag }}
          IMAGE_TAG: ${{ needs.build-and-test.outputs.image-tag }}
        run: |
          set -e

          # Set error handling
          trap 'echo "‚ùå Deployment failed at line $LINENO"' ERR

          echo "üöÄ Starting deployment..."
          echo "Core Image: $CORE_IMAGE"
          echo "Users Image: $USERS_IMAGE"
          echo "Namespace: $KUBE_NAMESPACE"

          # Function for retry logic
          retry_command() {
            local max_attempts=3
            local attempt=1
            local command="$1"
            
            while [ $attempt -le $max_attempts ]; do
              echo "Attempt $attempt/$max_attempts: $command"
              if eval "$command"; then
                return 0
              fi
              attempt=$((attempt + 1))
              [ $attempt -le $max_attempts ] && sleep 10
            done
            echo "Command failed after $max_attempts attempts: $command"
            return 1
          }

          # Install cri-dockerd if running as root and using none driver
          install_cri_dockerd() {
            if command -v cri-dockerd >/dev/null 2>&1; then
              echo "‚úÖ cri-dockerd already installed"
              return 0
            fi
            
            echo "üì¶ Installing cri-dockerd..."
            
            # Download and install cri-dockerd
            CRI_DOCKERD_VERSION="0.3.8"
            wget -q "https://github.com/Mirantis/cri-dockerd/releases/download/v${CRI_DOCKERD_VERSION}/cri-dockerd-${CRI_DOCKERD_VERSION}.amd64.tgz"
            tar xzf "cri-dockerd-${CRI_DOCKERD_VERSION}.amd64.tgz"
            sudo mv cri-dockerd/cri-dockerd /usr/local/bin/
            rm -rf cri-dockerd*
            
            # Create systemd service files
            sudo tee /etc/systemd/system/cri-docker.service > /dev/null <<EOF
          [Unit]
          Description=CRI Interface for Docker Application Container Engine
          Documentation=https://docs.mirantis.com
          After=network-online.target firewalld.service docker.service
          Wants=network-online.target
          Requires=cri-docker.socket

          [Service]
          Type=notify
          ExecStart=/usr/local/bin/cri-dockerd --container-runtime-endpoint fd://
          ExecReload=/bin/kill -s HUP \$MAINPID
          TimeoutSec=0
          RestartSec=2
          Restart=always

          [Install]
          WantedBy=multi-user.target
          EOF

            sudo tee /etc/systemd/system/cri-docker.socket > /dev/null <<EOF
          [Unit]
          Description=CRI Docker Socket for the API
          PartOf=cri-docker.service

          [Socket]
          ListenStream=%t/cri-dockerd.sock
          SocketMode=0660
          SocketUser=root
          SocketGroup=docker

          [Install]
          WantedBy=sockets.target
          EOF

            # Enable and start cri-dockerd
            sudo systemctl daemon-reload
            sudo systemctl enable cri-docker.service
            sudo systemctl enable cri-docker.socket
            sudo systemctl start cri-docker.service
            sudo systemctl start cri-docker.socket
            
            echo "‚úÖ cri-dockerd installed and started"
          }

          # Check/Start Minikube with retry
          echo "Checking Minikube status..."
          if ! (minikube status 2>/dev/null | grep -q "host: Running" && kubectl cluster-info 2>/dev/null); then
            echo "Starting Minikube cluster..."
            minikube delete 2>/dev/null || true
            
            # Use appropriate driver based on environment
            if [ "$(id -u)" -eq 0 ]; then
              echo "Running as root, using none driver with containerd"
              
              # Install cri-dockerd if needed
              install_cri_dockerd
              
              # Use containerd runtime instead of docker to avoid cri-dockerd issues
              retry_command "minikube start --driver=none --container-runtime=containerd --kubernetes-version=v1.28.3 --wait=all"
            else
              echo "Running as non-root, using docker driver"
              retry_command "minikube start --driver=docker --kubernetes-version=v1.28.3 --memory=4096 --cpus=2 --disk-size=15g --wait=all"
            fi
            
            minikube addons enable ingress
            kubectl wait --for=condition=Ready nodes --all --timeout=180s
          fi

          MINIKUBE_IP=$(minikube ip)
          echo "Minikube IP: $MINIKUBE_IP"

          # Optimized image handling
          echo "Managing Docker images..."

          # Check if images exist locally first
          if ! docker image inspect "$CORE_IMAGE" >/dev/null 2>&1; then
            echo "Pulling Core API image..."
            retry_command "docker pull $CORE_IMAGE"
          fi

          if ! docker image inspect "$USERS_IMAGE" >/dev/null 2>&1; then
            echo "Pulling Users API image..."
            retry_command "docker pull $USERS_IMAGE"
          fi

          # Load images to minikube efficiently (different approach for none driver)
          if [ "$(id -u)" -eq 0 ]; then
            echo "‚úÖ Using none driver with containerd - images will be pulled directly by kubelet"
            # For none driver with containerd, we need to tag images for containerd
            sudo ctr -n k8s.io images import <(docker save "$CORE_IMAGE") || echo "Core image import failed, will pull from registry"
            sudo ctr -n k8s.io images import <(docker save "$USERS_IMAGE") || echo "Users image import failed, will pull from registry"
          else
            if ! minikube image ls | grep -q "$IMAGE_TAG"; then
              echo "Loading images to Minikube..."
              minikube image load "$CORE_IMAGE" &
              minikube image load "$USERS_IMAGE" &
              wait
              echo "‚úÖ Images loaded to Minikube"
            else
              echo "‚úÖ Images already present in Minikube"
            fi
          fi

          # Deploy Kubernetes resources with better error handling
          echo "Deploying Kubernetes resources..."

          # Create namespace
          kubectl create namespace $KUBE_NAMESPACE --dry-run=client -o yaml | kubectl apply -f -

          # Apply configurations
          [ -f k8s/secrets.yaml ] && kubectl apply -f k8s/secrets.yaml -n $KUBE_NAMESPACE
          [ -f k8s/configmap.yaml ] && kubectl apply -f k8s/configmap.yaml -n $KUBE_NAMESPACE

          # Deploy PostgreSQL if not exists
          if ! kubectl get deployment postgres -n $KUBE_NAMESPACE >/dev/null 2>&1; then
            [ -f k8s/postgres/deployment.yaml ] && kubectl apply -f k8s/postgres/deployment.yaml -n $KUBE_NAMESPACE
          fi

          # Deploy APIs
          [ -d k8s/core-api ] && kubectl apply -f k8s/core-api/ -n $KUBE_NAMESPACE
          [ -d k8s/users-api ] && kubectl apply -f k8s/users-api/ -n $KUBE_NAMESPACE

          # Update images
          kubectl set image deployment/core-api core-api=$CORE_IMAGE -n $KUBE_NAMESPACE --record
          kubectl set image deployment/users-api users-api=$USERS_IMAGE -n $KUBE_NAMESPACE --record

          # Apply environment patches
          kubectl patch deployment core-api -n $KUBE_NAMESPACE --type='merge' -p='{
            "spec": {
              "template": {
                "spec": {
                  "containers": [{
                    "name": "core-api",
                    "env": [
                      {"name": "ASPNETCORE_ENVIRONMENT", "value": "Production"},
                      {"name": "ASPNETCORE_URLS", "value": "http://+:8080"}
                    ]
                  }]
                }
              }
            }
          }' 2>/dev/null || echo "Core API patch already applied"

          kubectl patch deployment users-api -n $KUBE_NAMESPACE --type='merge' -p='{
            "spec": {
              "template": {
                "spec": {
                  "containers": [{
                    "name": "users-api",
                    "env": [
                      {"name": "ASPNETCORE_ENVIRONMENT", "value": "Production"},
                      {"name": "ASPNETCORE_URLS", "value": "http://+:8080"}
                    ]
                  }]
                }
              }
            }
          }' 2>/dev/null || echo "Users API patch already applied"

          # Wait for deployments with improved monitoring
          echo "Waiting for deployments to be ready..."

          # Wait for PostgreSQL first
          if kubectl get deployment postgres -n $KUBE_NAMESPACE >/dev/null 2>&1; then
            if ! kubectl get pods -l app=postgres -n $KUBE_NAMESPACE -o jsonpath='{.items[0].status.phase}' 2>/dev/null | grep -q "Running"; then
              kubectl rollout status deployment/postgres -n $KUBE_NAMESPACE --timeout=$KUBECTL_TIMEOUT
            fi
          fi

          # Wait for APIs in parallel
          kubectl rollout status deployment/core-api -n $KUBE_NAMESPACE --timeout=$KUBECTL_TIMEOUT &
          CORE_PID=$!
          kubectl rollout status deployment/users-api -n $KUBE_NAMESPACE --timeout=$KUBECTL_TIMEOUT &
          USERS_PID=$!

          # Wait for both deployments
          wait $CORE_PID && echo "‚úÖ Core API deployment ready" || echo "‚ùå Core API deployment failed"
          wait $USERS_PID && echo "‚úÖ Users API deployment ready" || echo "‚ùå Users API deployment failed"

          echo "‚úÖ All deployments processed!"

          # Enhanced health checks with proper error handling
          echo "Performing health checks..."

          health_check() {
            local url=$1
            local service_name=$2
            local max_attempts=15
            local attempt=1
            
            while [ $attempt -le $max_attempts ]; do
              if curl -s --connect-timeout 5 --max-time 10 "$url" >/dev/null 2>&1; then
                echo "‚úÖ $service_name is healthy"
                return 0
              fi
              echo "Waiting for $service_name... (attempt $attempt/$max_attempts)"
              sleep 10
              attempt=$((attempt + 1))
            done
            echo "‚ö†Ô∏è $service_name health check timeout"
            return 1
          }

          # Get the appropriate IP for health checks
          if [ "$(id -u)" -eq 0 ]; then
            # For none driver, use localhost or node IP
            HEALTH_CHECK_IP="localhost"
          else
            # For docker driver, use minikube IP
            HEALTH_CHECK_IP="$MINIKUBE_IP"
          fi

          health_check "http://$HEALTH_CHECK_IP:30301/" "Core API" &
          health_check "http://$HEALTH_CHECK_IP:30302/" "Users API" &
          wait

          # Final status report
          echo ""
          echo "üöÄ Deployment Complete!"
          echo "=================================="
          echo "Core API: http://$HEALTH_CHECK_IP:30301"
          echo "Users API: http://$HEALTH_CHECK_IP:30302"
          echo "Image Tag: $IMAGE_TAG"
          echo ""
          echo "Pod Status:"
          kubectl get pods -n $KUBE_NAMESPACE --no-headers | awk '{print "  " $1": "$3}'

          # Cleanup old images to save space
          docker image prune -f --filter "until=24h" >/dev/null 2>&1 || true

      - name: üßπ Cleanup on failure
        if: failure()
        run: |
          kubectl delete pods --field-selector=status.phase=Failed -n $KUBE_NAMESPACE --ignore-not-found=true
          docker system prune -f --filter "until=1h" >/dev/null 2>&1 || true

          # Set error handling
          trap 'echo "‚ùå Deployment failed at line $LINENO"' ERR

          # Export variables for remote execution with validation
          export CORE_IMAGE="${{ env.IMAGE_CORE }}:${{ env.IMAGE_TAG }}"
          export USERS_IMAGE="${{ env.IMAGE_USERS }}:${{ env.IMAGE_TAG }}"
          export KUBE_NAMESPACE="${{ env.KUBE_NAMESPACE }}"
          export KUBECTL_TIMEOUT="${{ env.KUBECTL_TIMEOUT }}"
          export REGISTRY_URL="${{ env.REGISTRY_URL }}"
          export REGISTRY_USERNAME="${{ env.REGISTRY_USERNAME }}"
          export REGISTRY_PASSWORD="${{ env.REGISTRY_PASSWORD }}"

          # Validate required variables
          for var in CORE_IMAGE USERS_IMAGE KUBE_NAMESPACE KUBECTL_TIMEOUT REGISTRY_URL REGISTRY_USERNAME REGISTRY_PASSWORD; do
            if [ -z "${!var}" ]; then
              echo "‚ùå Required variable $var is not set"
              exit 1
            fi
          done

          echo "üöÄ Starting deployment on remote server..."
          echo "Core Image: $CORE_IMAGE"
          echo "Users Image: $USERS_IMAGE"
          echo "Namespace: $KUBE_NAMESPACE"

          # Function for retry logic
          retry_command() {
            local max_attempts=3
            local attempt=1
            local command="$1"
            
            while [ $attempt -le $max_attempts ]; do
              echo "Attempt $attempt/$max_attempts: $command"
              if eval "$command"; then
                return 0
              fi
              attempt=$((attempt + 1))
              [ $attempt -le $max_attempts ] && sleep 10
            done
            echo "Command failed after $max_attempts attempts: $command"
            return 1
          }

          # Install cri-dockerd if running as root and using none driver
          install_cri_dockerd() {
            if command -v cri-dockerd >/dev/null 2>&1; then
              echo "‚úÖ cri-dockerd already installed"
              return 0
            fi
            
            echo "üì¶ Installing cri-dockerd..."
            
            # Download and install cri-dockerd
            CRI_DOCKERD_VERSION="0.3.8"
            wget -q "https://github.com/Mirantis/cri-dockerd/releases/download/v${CRI_DOCKERD_VERSION}/cri-dockerd-${CRI_DOCKERD_VERSION}.amd64.tgz"
            tar xzf "cri-dockerd-${CRI_DOCKERD_VERSION}.amd64.tgz"
            sudo mv cri-dockerd/cri-dockerd /usr/local/bin/
            rm -rf cri-dockerd*
            
            # Create systemd service files
            sudo tee /etc/systemd/system/cri-docker.service > /dev/null <<EOF
          [Unit]
          Description=CRI Interface for Docker Application Container Engine
          Documentation=https://docs.mirantis.com
          After=network-online.target firewalld.service docker.service
          Wants=network-online.target
          Requires=cri-docker.socket

          [Service]
          Type=notify
          ExecStart=/usr/local/bin/cri-dockerd --container-runtime-endpoint fd://
          ExecReload=/bin/kill -s HUP \$MAINPID
          TimeoutSec=0
          RestartSec=2
          Restart=always

          [Install]
          WantedBy=multi-user.target
          EOF

            sudo tee /etc/systemd/system/cri-docker.socket > /dev/null <<EOF
          [Unit]
          Description=CRI Docker Socket for the API
          PartOf=cri-docker.service

          [Socket]
          ListenStream=%t/cri-dockerd.sock
          SocketMode=0660
          SocketUser=root
          SocketGroup=docker

          [Install]
          WantedBy=sockets.target
          EOF

            # Enable and start cri-dockerd
            sudo systemctl daemon-reload
            sudo systemctl enable cri-docker.service
            sudo systemctl enable cri-docker.socket
            sudo systemctl start cri-docker.service
            sudo systemctl start cri-docker.socket
            
            echo "‚úÖ cri-dockerd installed and started"
          }

          # Check/Start Minikube with retry
          echo "Checking Minikube status..."
          if ! (minikube status 2>/dev/null | grep -q "host: Running" && kubectl cluster-info 2>/dev/null); then
            echo "Starting Minikube cluster..."
            minikube delete 2>/dev/null || true
            retry_command "minikube start --driver=docker --kubernetes-version=v1.28.3 --memory=4096 --cpus=2 --disk-size=15g --wait=all"
            minikube addons enable ingress
            kubectl wait --for=condition=Ready nodes --all --timeout=180s
          fi

          MINIKUBE_IP=$(minikube ip)
          echo "Minikube IP: $MINIKUBE_IP"

          # Login to Docker registry
          echo "Logging into Docker registry..."
          echo "$REGISTRY_PASSWORD" | docker login $REGISTRY_URL -u "$REGISTRY_USERNAME" --password-stdin

          # Optimized image handling
          echo "Managing Docker images..."

          # Check if images exist locally first
          if ! docker image inspect "$CORE_IMAGE" >/dev/null 2>&1; then
            echo "Pulling Core API image..."
            retry_command "docker pull $CORE_IMAGE"
          fi

          if ! docker image inspect "$USERS_IMAGE" >/dev/null 2>&1; then
            echo "Pulling Users API image..."
            retry_command "docker pull $USERS_IMAGE"
          fi

          # Load images to minikube efficiently
          if ! minikube image ls | grep -q "${{ env.IMAGE_TAG }}"; then
            echo "Loading images to Minikube..."
            minikube image load "$CORE_IMAGE" &
            minikube image load "$USERS_IMAGE" &
            wait
            echo "‚úÖ Images loaded to Minikube"
          else
            echo "‚úÖ Images already present in Minikube"
          fi

          # Deploy Kubernetes resources with better error handling
          echo "Deploying Kubernetes resources..."
          cd ~/deployment

          # Create namespace
          kubectl create namespace $KUBE_NAMESPACE --dry-run=client -o yaml | kubectl apply -f -

          # Apply configurations
          [ -f k8s/secrets.yaml ] && kubectl apply -f k8s/secrets.yaml -n $KUBE_NAMESPACE
          [ -f k8s/configmap.yaml ] && kubectl apply -f k8s/configmap.yaml -n $KUBE_NAMESPACE

          # Deploy PostgreSQL if not exists
          if ! kubectl get deployment postgres -n $KUBE_NAMESPACE >/dev/null 2>&1; then
            [ -f k8s/postgres/deployment.yaml ] && kubectl apply -f k8s/postgres/deployment.yaml -n $KUBE_NAMESPACE
          fi

          # Deploy APIs
          [ -d k8s/core-api ] && kubectl apply -f k8s/core-api/ -n $KUBE_NAMESPACE
          [ -d k8s/users-api ] && kubectl apply -f k8s/users-api/ -n $KUBE_NAMESPACE

          # Update images
          kubectl set image deployment/core-api core-api=$CORE_IMAGE -n $KUBE_NAMESPACE --record
          kubectl set image deployment/users-api users-api=$USERS_IMAGE -n $KUBE_NAMESPACE --record

          # Apply environment patches
          kubectl patch deployment core-api -n $KUBE_NAMESPACE --type='merge' -p='{
            "spec": {
              "template": {
                "spec": {
                  "containers": [{
                    "name": "core-api",
                    "env": [
                      {"name": "ASPNETCORE_ENVIRONMENT", "value": "Production"},
                      {"name": "ASPNETCORE_URLS", "value": "http://+:8080"}
                    ]
                  }]
                }
              }
            }
          }' 2>/dev/null || echo "Core API patch already applied"

          kubectl patch deployment users-api -n $KUBE_NAMESPACE --type='merge' -p='{
            "spec": {
              "template": {
                "spec": {
                  "containers": [{
                    "name": "users-api",
                    "env": [
                      {"name": "ASPNETCORE_ENVIRONMENT", "value": "Production"},
                      {"name": "ASPNETCORE_URLS", "value": "http://+:8080"}
                    ]
                  }]
                }
              }
            }
          }' 2>/dev/null || echo "Users API patch already applied"

          # Wait for deployments with improved monitoring
          echo "Waiting for deployments to be ready..."

          # Wait for PostgreSQL first
          if kubectl get deployment postgres -n $KUBE_NAMESPACE >/dev/null 2>&1; then
            if ! kubectl get pods -l app=postgres -n $KUBE_NAMESPACE -o jsonpath='{.items[0].status.phase}' 2>/dev/null | grep -q "Running"; then
              kubectl rollout status deployment/postgres -n $KUBE_NAMESPACE --timeout=$KUBECTL_TIMEOUT
            fi
          fi

          # Wait for APIs in parallel
          kubectl rollout status deployment/core-api -n $KUBE_NAMESPACE --timeout=$KUBECTL_TIMEOUT &
          CORE_PID=$!
          kubectl rollout status deployment/users-api -n $KUBE_NAMESPACE --timeout=$KUBECTL_TIMEOUT &
          USERS_PID=$!

          # Wait for both deployments
          wait $CORE_PID && echo "‚úÖ Core API deployment ready" || echo "‚ùå Core API deployment failed"
          wait $USERS_PID && echo "‚úÖ Users API deployment ready" || echo "‚ùå Users API deployment failed"

          echo "‚úÖ All deployments processed!"

          # Enhanced health checks with proper error handling
          echo "Performing health checks..."

          health_check() {
            local url=$1
            local service_name=$2
            local max_attempts=15
            local attempt=1
            
            while [ $attempt -le $max_attempts ]; do
              if curl -s --connect-timeout 5 --max-time 10 "$url" >/dev/null 2>&1; then
                echo "‚úÖ $service_name is healthy"
                return 0
              fi
              echo "Waiting for $service_name... (attempt $attempt/$max_attempts)"
              sleep 10
              attempt=$((attempt + 1))
            done
            echo "‚ö†Ô∏è $service_name health check timeout"
            return 1
          }

          health_check "http://$MINIKUBE_IP:30301/" "Core API" &
          health_check "http://$MINIKUBE_IP:30302/" "Users API" &
          wait

          # Final status report
          echo ""
          echo "üöÄ Deployment Complete!"
          echo "=================================="
          echo "Core API: http://$MINIKUBE_IP:30301"
          echo "Users API: http://$MINIKUBE_IP:30302"
          echo "Image Tag: ${{ env.IMAGE_TAG }}"
          echo ""
          echo "Pod Status:"
          kubectl get pods -n $KUBE_NAMESPACE --no-headers | awk '{print "  " $1": "$3}'

          # Cleanup old images to save space
          docker image prune -f --filter "until=24h" >/dev/null 2>&1 || true

          EOF

      - name: üßπ Cleanup on failure
        if: failure()
        run: |
          kubectl delete pods --field-selector=status.phase=Failed -n $KUBE_NAMESPACE --ignore-not-found=true
          docker system prune -f --filter "until=1h" >/dev/null 2>&1 || true
          echo "‚úÖ Cleanup completed"
          echo "‚ùå Deployment failed, cleanup executed"

