name: CI/CD Pipeline - Ecommerce Platform

on:
  push:
    branches: [main]
  workflow_dispatch:

env:
  DOTNET_VERSION: "9.0"
  REGISTRY_URL: ${{ secrets.REGISTRY_URL }}
  REGISTRY_USERNAME: ${{ secrets.REGISTRY_USERNAME }}
  REGISTRY_PASSWORD: ${{ secrets.REGISTRY_PASSWORD }}
  IMAGE_CORE: moclaw/ecom-core-api
  IMAGE_USERS: moclaw/ecom-users-api
  KUBE_NAMESPACE: ecommerce
  CF_TUNNEL_HOST: ${{ secrets.CF_TUNNEL_HOST }}
  CF_TUNNEL_USER: ${{ secrets.CF_TUNNEL_USER }}
  KUBECTL_TIMEOUT: 300s
  HEALTH_CHECK_TIMEOUT: 180s

jobs:
  build-and-test:
    name: Build & Test
    runs-on: ubuntu-latest
    outputs:
      image-tag: ${{ steps.meta.outputs.tags }}
      should-deploy: ${{ steps.changes.outputs.should-deploy }}

    steps:
      - name: ðŸ“¥ Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: ðŸ” Check for changes
        id: changes
        run: |
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            echo "should-deploy=true" >> $GITHUB_OUTPUT
            echo "Manual trigger - will deploy"
          elif [ "${{ github.ref }}" = "refs/heads/main" ]; then
            echo "should-deploy=true" >> $GITHUB_OUTPUT
            echo "Main branch - will deploy"
          else
            if git diff --name-only HEAD~1 HEAD | grep -E "\\.(cs|csproj|sln|Dockerfile)$|^k8s/"; then
              echo "should-deploy=true" >> $GITHUB_OUTPUT
              echo "Source code changes detected - will deploy"
            else
              echo "should-deploy=false" >> $GITHUB_OUTPUT
              echo "No significant changes - skipping deployment"
            fi
          fi

      - name: ðŸ”§ Setup .NET SDK
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}

      - name: ðŸ“¦ Cache NuGet packages
        uses: actions/cache@v4
        with:
          path: ~/.nuget/packages
          key: ${{ runner.os }}-nuget-${{ hashFiles('**/*.csproj', '**/*.props', '**/*.targets') }}
          restore-keys: |
            ${{ runner.os }}-nuget-

      - name: ðŸ“¦ Restore dependencies
        run: |
          dotnet restore Moclaw.Ecommerce.sln --verbosity minimal

      - name: ðŸ—ï¸ Build solution
        run: |
          dotnet build Moclaw.Ecommerce.sln --configuration Release --no-restore --verbosity minimal

      - name: ðŸ§ª Run tests
        run: |
          if find . -name "*.Test*.csproj" -o -name "*Test.csproj" | head -1 | grep -q .; then
            echo "Running unit tests..."
            dotnet test --configuration Release --no-build --verbosity minimal --parallel
          else
            echo "No test projects found, skipping tests"
          fi

      - name: ðŸ·ï¸ Generate metadata
        id: meta
        run: |
          TAG="${{ github.sha }}"
          SHORT_SHA="${TAG:0:8}"
          echo "tags=${SHORT_SHA}" >> $GITHUB_OUTPUT
  build-images:
    name: Build Images
    runs-on: ubuntu-latest
    needs: build-and-test
    if: needs.build-and-test.outputs.should-deploy == 'true'
    strategy:
      matrix:
        service:
          - name: core-api
            dockerfile: Ecom.Core/src/Ecom.Core.API/Dockerfile
            image_name: moclaw/ecom-core-api
          - name: users-api
            dockerfile: Ecom.Users/src/Ecom.Users.API/Dockerfile
            image_name: moclaw/ecom-users-api
      fail-fast: false
      max-parallel: 2

    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ðŸ³ Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: ðŸ” Login to Docker registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY_URL }}
          username: ${{ env.REGISTRY_USERNAME }}
          password: ${{ env.REGISTRY_PASSWORD }}

      - name: ðŸ—ï¸ Build and push ${{ matrix.service.name }}
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ${{ matrix.service.dockerfile }}
          push: true
          tags: |
            ${{ matrix.service.image_name }}:${{ needs.build-and-test.outputs.image-tag }}
            ${{ matrix.service.image_name }}:latest
          platforms: linux/amd64
          cache-from: type=registry,ref=${{ matrix.service.image_name }}:buildcache
          cache-to: type=registry,ref=${{ matrix.service.image_name }}:buildcache,mode=max
          build-args: |
            BUILDKIT_INLINE_CACHE=1
  deploy-minikube:
    name: Deploy via SSH
    runs-on: ubuntu-latest
    needs: [build-and-test, build-images]
    if: needs.build-and-test.outputs.should-deploy == 'true'

    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ðŸ” Setup SSH
        shell: bash
        env:
          SSH_PRIVATE_KEY: ${{ secrets.SSH_PRIVATE_KEY }}
          CF_TUNNEL_HOST: ${{ secrets.CF_TUNNEL_HOST }}
          CF_TUNNEL_USER: ${{ secrets.CF_TUNNEL_USER }}
        run: |
          echo "$SSH_PRIVATE_KEY" | tr -d '\r' > deploy_key
          chmod 600 deploy_key
          ssh-keyscan -H "$CF_TUNNEL_HOST" >> known_hosts
          ssh -i deploy_key -o UserKnownHostsFile=known_hosts -o ConnectTimeout=10 -o StrictHostKeyChecking=no "$CF_TUNNEL_USER@$CF_TUNNEL_HOST" "echo 'SSH connection successful'"

      - name: ðŸ“¤ Transfer deployment files
        env:
          CF_TUNNEL_HOST: ${{ secrets.CF_TUNNEL_HOST }}
          CF_TUNNEL_USER: ${{ secrets.CF_TUNNEL_USER }}
        run: |
          tar -czf deployment.tar.gz k8s/ .github/scripts/ 2>/dev/null || tar -czf deployment.tar.gz k8s/
          scp -i deploy_key -o UserKnownHostsFile=known_hosts -o StrictHostKeyChecking=no deployment.tar.gz "$CF_TUNNEL_USER@$CF_TUNNEL_HOST":~/
          ssh -i deploy_key -o UserKnownHostsFile=known_hosts -o StrictHostKeyChecking=no "$CF_TUNNEL_USER@$CF_TUNNEL_HOST" '
            rm -rf ~/deployment
            mkdir -p ~/deployment
            tar -xzf ~/deployment.tar.gz -C ~/deployment
            rm ~/deployment.tar.gz
          '

      - name: ðŸš€ Deploy to Minikube (Remote)
        env:
          CF_TUNNEL_HOST: ${{ secrets.CF_TUNNEL_HOST }}
          CF_TUNNEL_USER: ${{ secrets.CF_TUNNEL_USER }}
          REGISTRY_PASSWORD: ${{ secrets.REGISTRY_PASSWORD }}
          REGISTRY_URL: ${{ secrets.REGISTRY_URL }}
          REGISTRY_USERNAME: ${{ secrets.REGISTRY_USERNAME }}
          IMAGE_TAG: ${{ needs.build-and-test.outputs.image-tag }}
        run: |
          ssh -i deploy_key -o UserKnownHostsFile=known_hosts -o StrictHostKeyChecking=no "$CF_TUNNEL_USER@$CF_TUNNEL_HOST" << 'EOF'
          set -e

          # Export variables for remote execution
          export CORE_IMAGE="${{ env.IMAGE_CORE }}:${{ env.IMAGE_TAG }}"
          export USERS_IMAGE="${{ env.IMAGE_USERS }}:${{ env.IMAGE_TAG }}"
          export KUBE_NAMESPACE="${{ env.KUBE_NAMESPACE }}"
          export KUBECTL_TIMEOUT="${{ env.KUBECTL_TIMEOUT }}"
          export REGISTRY_URL="${{ env.REGISTRY_URL }}"
          export REGISTRY_USERNAME="${{ env.REGISTRY_USERNAME }}"
          export REGISTRY_PASSWORD="${{ env.REGISTRY_PASSWORD }}"

          echo "ðŸš€ Starting deployment on remote server..."
          echo "Core Image: $CORE_IMAGE"
          echo "Users Image: $USERS_IMAGE"

          # Function for retry logic
          retry_command() {
            local max_attempts=3
            local attempt=1
            local command="$1"
            
            while [ $attempt -le $max_attempts ]; do
              echo "Attempt $attempt/$max_attempts: $command"
              if eval "$command"; then
                return 0
              fi
              attempt=$((attempt + 1))
              [ $attempt -le $max_attempts ] && sleep 10
            done
            echo "Command failed after $max_attempts attempts: $command"
            return 1
          }

          # Check/Start Minikube with retry
          echo "Checking Minikube status..."
          if ! (minikube status 2>/dev/null | grep -q "host: Running" && kubectl cluster-info 2>/dev/null); then
            echo "Starting Minikube cluster..."
            minikube delete 2>/dev/null || true
            retry_command "minikube start --driver=docker --kubernetes-version=v1.28.3 --memory=4096 --cpus=2 --disk-size=15g --wait=all"
            minikube addons enable ingress
            kubectl wait --for=condition=Ready nodes --all --timeout=180s
          fi

          MINIKUBE_IP=$(minikube ip)
          echo "Minikube IP: $MINIKUBE_IP"

          # Login to Docker registry
          echo "Logging into Docker registry..."
          echo "$REGISTRY_PASSWORD" | docker login $REGISTRY_URL -u "$REGISTRY_USERNAME" --password-stdin

          # Optimized image handling
          echo "Managing Docker images..."

          # Check if images exist locally first
          if ! docker image inspect "$CORE_IMAGE" >/dev/null 2>&1; then
            echo "Pulling Core API image..."
            retry_command "docker pull $CORE_IMAGE"
          fi

          if ! docker image inspect "$USERS_IMAGE" >/dev/null 2>&1; then
            echo "Pulling Users API image..."
            retry_command "docker pull $USERS_IMAGE"
          fi

          # Load images to minikube efficiently
          if ! minikube image ls | grep -q "${{ env.IMAGE_TAG }}"; then
            echo "Loading images to Minikube..."
            minikube image load "$CORE_IMAGE" &
            minikube image load "$USERS_IMAGE" &
            wait
            echo "âœ… Images loaded to Minikube"
          else
            echo "âœ… Images already present in Minikube"
          fi

          # Deploy Kubernetes resources with better error handling
          echo "Deploying Kubernetes resources..."
          cd ~/deployment

          # Create namespace
          kubectl create namespace $KUBE_NAMESPACE --dry-run=client -o yaml | kubectl apply -f -

          # Apply configurations
          [ -f k8s/secrets.yaml ] && kubectl apply -f k8s/secrets.yaml -n $KUBE_NAMESPACE
          [ -f k8s/configmap.yaml ] && kubectl apply -f k8s/configmap.yaml -n $KUBE_NAMESPACE

          # Deploy PostgreSQL if not exists
          if ! kubectl get deployment postgres -n $KUBE_NAMESPACE >/dev/null 2>&1; then
            [ -f k8s/postgres/deployment.yaml ] && kubectl apply -f k8s/postgres/deployment.yaml -n $KUBE_NAMESPACE
          fi

          # Deploy APIs
          [ -d k8s/core-api ] && kubectl apply -f k8s/core-api/ -n $KUBE_NAMESPACE
          [ -d k8s/users-api ] && kubectl apply -f k8s/users-api/ -n $KUBE_NAMESPACE

          # Update images
          kubectl set image deployment/core-api core-api=$CORE_IMAGE -n $KUBE_NAMESPACE --record
          kubectl set image deployment/users-api users-api=$USERS_IMAGE -n $KUBE_NAMESPACE --record

          # Apply environment patches
          kubectl patch deployment core-api -n $KUBE_NAMESPACE --type='merge' -p='{
            "spec": {
              "template": {
                "spec": {
                  "containers": [{
                    "name": "core-api",
                    "env": [
                      {"name": "ASPNETCORE_ENVIRONMENT", "value": "Production"},
                      {"name": "ASPNETCORE_URLS", "value": "http://+:8080"}
                    ]
                  }]
                }
              }
            }
          }' 2>/dev/null || echo "Core API patch already applied"

          kubectl patch deployment users-api -n $KUBE_NAMESPACE --type='merge' -p='{
            "spec": {
              "template": {
                "spec": {
                  "containers": [{
                    "name": "users-api",
                    "env": [
                      {"name": "ASPNETCORE_ENVIRONMENT", "value": "Production"},
                      {"name": "ASPNETCORE_URLS", "value": "http://+:8080"}
                    ]
                  }]
                }
              }
            }
          }' 2>/dev/null || echo "Users API patch already applied"

          # Wait for deployments with improved monitoring
          echo "Waiting for deployments to be ready..."

          # Wait for PostgreSQL first
          if kubectl get deployment postgres -n $KUBE_NAMESPACE >/dev/null 2>&1; then
            if ! kubectl get pods -l app=postgres -n $KUBE_NAMESPACE -o jsonpath='{.items[0].status.phase}' 2>/dev/null | grep -q "Running"; then
              kubectl rollout status deployment/postgres -n $KUBE_NAMESPACE --timeout=$KUBECTL_TIMEOUT
            fi
          fi

          # Wait for APIs in parallel
          kubectl rollout status deployment/core-api -n $KUBE_NAMESPACE --timeout=$KUBECTL_TIMEOUT &
          CORE_PID=$!
          kubectl rollout status deployment/users-api -n $KUBE_NAMESPACE --timeout=$KUBECTL_TIMEOUT &
          USERS_PID=$!

          # Wait for both deployments
          wait $CORE_PID && echo "âœ… Core API deployment ready" || echo "âŒ Core API deployment failed"
          wait $USERS_PID && echo "âœ… Users API deployment ready" || echo "âŒ Users API deployment failed"

          echo "âœ… All deployments processed!"

          # Enhanced health checks with proper error handling
          echo "Performing health checks..."

          health_check() {
            local url=$1
            local service_name=$2
            local max_attempts=15
            local attempt=1
            
            while [ $attempt -le $max_attempts ]; do
              if curl -s --connect-timeout 5 --max-time 10 "$url" >/dev/null 2>&1; then
                echo "âœ… $service_name is healthy"
                return 0
              fi
              echo "Waiting for $service_name... (attempt $attempt/$max_attempts)"
              sleep 10
              attempt=$((attempt + 1))
            done
            echo "âš ï¸ $service_name health check timeout"
            return 1
          }

          health_check "http://$MINIKUBE_IP:30301/" "Core API" &
          health_check "http://$MINIKUBE_IP:30302/" "Users API" &
          wait

          # Final status report
          echo ""
          echo "ðŸš€ Deployment Complete!"
          echo "=================================="
          echo "Core API: http://$MINIKUBE_IP:30301"
          echo "Users API: http://$MINIKUBE_IP:30302"
          echo "Image Tag: ${{ env.IMAGE_TAG }}"
          echo ""
          echo "Pod Status:"
          kubectl get pods -n $KUBE_NAMESPACE --no-headers | awk '{print "  " $1": "$3}'

          # Cleanup old images to save space
          docker image prune -f --filter "until=24h" >/dev/null 2>&1 || true

          EOF

      - name: ðŸ§¹ Cleanup SSH
        if: always()
        run: |
          rm -f deploy_key known_hosts

      - name: ðŸ§¹ Remote cleanup on failure
        if: failure()
        env:
          CF_TUNNEL_HOST: ${{ secrets.CF_TUNNEL_HOST }}
          CF_TUNNEL_USER: ${{ secrets.CF_TUNNEL_USER }}
          KUBE_NAMESPACE: ${{ env.KUBE_NAMESPACE }}
        run: |
          if [ -f deploy_key ]; then
            ssh -i deploy_key -o UserKnownHostsFile=known_hosts -o StrictHostKeyChecking=no "$CF_TUNNEL_USER@$CF_TUNNEL_HOST" '
              kubectl delete pods --field-selector=status.phase=Failed -n '"$KUBE_NAMESPACE"' --ignore-not-found=true
              docker system prune -f --filter "until=1h" >/dev/null 2>&1 || true
              rm -rf ~/deployment
            ' || echo "Remote cleanup failed"
          fi
